{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31304a98",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m    101\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    104\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32mc:\\Users\\SAURABH SINGH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SAURABH SINGH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solution_base.py:372\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    366\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    368\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    369\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    370\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ======================\n",
    "# EXERCISE CONFIGURATION\n",
    "# ======================\n",
    "EXERCISES = {\n",
    "    \"bicep_curl\": {\n",
    "        \"landmarks\": {\n",
    "            \"joint1\": mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
    "            \"joint2\": mp_pose.PoseLandmark.LEFT_ELBOW,\n",
    "            \"joint3\": mp_pose.PoseLandmark.LEFT_WRIST\n",
    "        },\n",
    "        \"good_angles\": (30, 160),\n",
    "        \"feedback_rules\": {\n",
    "            \"elbow_stability\": {\"threshold\": 0.1, \"message\": \"Keep elbows stable!\"},\n",
    "            \"wrist_alignment\": {\"threshold\": 0.2, \"message\": \"Don't bend wrists!\"}\n",
    "        }\n",
    "    },\n",
    "    \"squat\": {\n",
    "        \"landmarks\": {\n",
    "            \"hip\": mp_pose.PoseLandmark.LEFT_HIP,\n",
    "            \"knee\": mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "            \"ankle\": mp_pose.PoseLandmark.LEFT_ANKLE\n",
    "        },\n",
    "        \"good_angles\": (80, 120),\n",
    "        \"feedback_rules\": {\n",
    "            \"knee_over_toes\": {\"threshold\": 0.15, \"message\": \"Knees over toes!\"},\n",
    "            \"back_angle\": {\"threshold\": 0.2, \"message\": \"Maintain neutral spine!\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "CURRENT_EXERCISE = \"bicep_curl\"  # Change to \"squat\" if needed\n",
    "\n",
    "# ======================\n",
    "# CORE LOGIC\n",
    "# ======================\n",
    "class ExerciseAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.feedback = []\n",
    "        self.rep_count = 0\n",
    "        self.stage = None\n",
    "\n",
    "    def calculate_angle(self, a, b, c):\n",
    "        a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(np.degrees(radians))\n",
    "        return angle if angle <= 180 else 360 - angle\n",
    "\n",
    "    def check_form(self, landmarks, exercise_config):\n",
    "        self.feedback = []\n",
    "        config = EXERCISES[exercise_config]\n",
    "        \n",
    "        joints = {name: [landmarks[joint.value].x, landmarks[joint.value].y] \n",
    "                  for name, joint in config[\"landmarks\"].items()}\n",
    "        \n",
    "        angle = self.calculate_angle(joints[\"joint1\"], joints[\"joint2\"], joints[\"joint3\"])\n",
    "        \n",
    "        # Feedback based on angle range\n",
    "        if not (config[\"good_angles\"][0] <= angle <= config[\"good_angles\"][1]):\n",
    "            self.feedback.append(f\"Adjust angle! Current: {angle:.1f}Â°\")\n",
    "        \n",
    "        # Exercise-specific feedback\n",
    "        if exercise_config == \"bicep_curl\":\n",
    "            if abs(joints[\"joint1\"][0] - joints[\"joint3\"][0]) > 0.1:\n",
    "                self.feedback.append(config[\"feedback_rules\"][\"elbow_stability\"][\"message\"])\n",
    "\n",
    "            # Curl rep counter\n",
    "            if angle > 160:\n",
    "                self.stage = \"down\"\n",
    "            if angle < 30 and self.stage == 'down':\n",
    "                self.stage = \"up\"\n",
    "                self.rep_count += 1\n",
    "\n",
    "        elif exercise_config == \"squat\":\n",
    "            if abs(joints[\"knee\"][0] - joints[\"ankle\"][0]) > 0.15:\n",
    "                self.feedback.append(config[\"feedback_rules\"][\"knee_over_toes\"][\"message\"])\n",
    "\n",
    "        return angle, self.feedback, self.rep_count, self.stage\n",
    "\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "# ======================\n",
    "analyzer = ExerciseAnalyzer()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # Preprocess frame\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            try:\n",
    "                angle, feedback, reps, stage = analyzer.check_form(\n",
    "                    results.pose_landmarks.landmark, \n",
    "                    CURRENT_EXERCISE\n",
    "                )\n",
    "\n",
    "                # Draw feedback text\n",
    "                y_offset = 30\n",
    "                for msg in feedback:\n",
    "                    cv2.putText(image, msg, (10, y_offset), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                    y_offset += 30\n",
    "\n",
    "                # Display angle\n",
    "                elbow = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "                coords = tuple(np.multiply([elbow.x, elbow.y], [640, 480]).astype(int))\n",
    "                cv2.putText(image, f\"{angle:.1f}Â°\", coords, \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "                # Render REP + STAGE counter box\n",
    "                cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "                cv2.putText(image, 'REPS', (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
    "                cv2.putText(image, str(reps), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "\n",
    "                cv2.putText(image, 'STAGE', (65, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
    "                cv2.putText(image, str(stage), (60, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Tracking Error: {e}\")\n",
    "\n",
    "            # Draw pose landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Show output\n",
    "        cv2.imshow('AI Gym Trainer', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
